# 2517290_rayane_correia_unifor_2025_big_data

Esse repositorio cont√©m o trabalho final da disciplina Big Data e Tecnologias de Armazenamento ministrada pelo professoer Nauber G√≥is
# üìä Pipeline de Dados ‚Äì Bolsa Fam√≠lia

Este reposit√≥rio cont√©m a implementa√ß√£o de um *pipeline de dados completo* para ingest√£o, processamento e organiza√ß√£o de dados do 
*Programa Bolsa Fam√≠lia*, utilizando **Spark, MinIO, Airflow e Docker**.
O projeto foi desenvolvido como parte da disciplina de Big Data ‚Äì P√≥s UNIFOR.

---

## üóÇ Estrutura do Projeto

```bash
üìÇ Big Data/
 ‚î£ üìÇ airflow/                      # Configura√ß√µes e DAGs do Apache Airflow
   ‚îÉ ‚î£ üìÇ dags #Armazenamento de dags
     ‚îÉ ‚î£ üìú pipeline_bolsa_familia.py   # Orquestra√ß√£o principal do pipeline
 ‚î£ üìÇ apps/                         # Scripts de aplica√ß√µes (extra√ß√£o, transforma√ß√£o, carga)
   ‚îÉ ‚î£ üìú api-to-bronze.py # Extra√ß√£o da API ‚Üí Bronze
   ‚îÉ ‚î£ üìú bronze-to-silver.py         # Transforma√ß√£o Bronze ‚Üí Silver
   ‚îÉ ‚î£ üìú gold_dim_municipio_gold.py       # Dimens√£o Munic√≠pio
   ‚îÉ ‚î£ üìú gold_dim_uf_gold.py              # Dimens√£o UF
   ‚îÉ ‚î£ üìú gold_fact_bolsa_familia.py  # Fato Bolsa Fam√≠lia
   ‚îÉ ‚îó üìú config_spark.py             # Configura√ß√£o do Spark (integra√ß√£o com MinIO)
 ‚î£ üìÇ data/                         # Armazenamento local simulado do Data Lake (MinIO)
   ‚îÉ ‚î£ üìÇ bronze-bolsa-familia-json   # Camada Bronze (dados brutos em JSON)
   ‚îÉ ‚î£ üìÇ silver-bolsa-familia-parquet # Camada Silver (dados tratados em Parquet)
   ‚îÉ ‚îó üìÇ gold-bolsa-familia-parquet   # Camada Gold (modelos dimensionais e fatos)
 ‚î£ üìÇ jars/                         # Depend√™ncias necess√°rias para Spark + MinIO
   ‚îÉ ‚î£ link_para_extrair_aws-java-sdk-bundle-1.12.767.txt #o Git barrou pelo tamanho mas o txt tem o link para Download
   ‚îÉ ‚îó hadoop-aws-3.3.4.jar
 ‚î£ üìú docker-compose.yml            # Orquestra√ß√£o dos servi√ßos (Airflow, MinIO, Spark, Postgres)
 ‚î£ üìú requirements.txt              # Depend√™ncias¬†Python
```
## üåê APIs utilizadas & como obter a chave

### APIs utilizadas (links oficiais)
- *Portal da Transpar√™ncia ‚Äì Bolsa Fam√≠lia (por munic√≠pio)*  
  Utilizada para a camada Bronze (ingest√£o de parcelas por munic√≠pio).
- *IBGE ‚Äì Localidades (Munic√≠pios/UF)*  
  Utilizada para refer√™ncia de c√≥digos IBGE e siglas de UF.

*Links √∫teis (documenta√ß√£o¬†e¬†cat√°logos)*
Portal da Transpar√™ncia ‚Äì Documenta√ß√£o geral:
https://portaldatransparencia.gov.br/api-de-dados

Portal da Transpar√™ncia ‚Äì Swagger (cat√°logo de endpoints):
https://api.portaldatransparencia.gov.br/

Portal da Transpar√™ncia ‚Äì Cadastro para obter a chave (token):
https://portaldatransparencia.gov.br/api-de-dados/cadastrar-email

Conecta gov.br ‚Äì Ficha do servi√ßo (como acessar a API):
https://www.gov.br/conecta/catalogo/apis/portal-da-transparencia-do-governo-federal

IBGE ‚Äì Documenta√ß√£o da API de Localidades:
https://servicodados.ibge.gov.br/api/docs/localidades 

## Como conseguir a chave (token) do Portal da Transpar√™ncia ‚Äî passo a passo
1) *Acesse* a p√°gina ‚ÄúAPI de dados ‚Äì Cadastro‚Äù do Portal da Transpar√™ncia e clique em *‚ÄúEntrar com gov.br‚Äù*.  
2) *Autentique-se* com sua conta gov.br (selo *Prata/Ouro*) *ou* com *CPF + senha* (neste caso, *habilite a verifica√ß√£o em duas etapas*).  
3) *Confirme o cadastro:* a chave de acesso (token) √© *enviada por e-mail* ao endere√ßo vinculado ao seu gov.br.  
4) *Guarde o token:* ele ser√° informado no cabe√ßalho das requisi√ß√µes quando voc√™ for usar a API em sistemas/relat√≥rios.  
5) *Aten√ß√£o aos limites:* existem limites por minuto; alguns endpoints (como *Bolsa Fam√≠lia por munic√≠pio*) ficam em uma cota mais restrita.  

> Observa√ß√£o pr√°tica: ao usar a API em qualquer ferramenta, inclua o token no cabe√ßalho conforme instru√ß√µes oficiais do Portal (chave chave-api-dados).

---



## üîÑ Fluxo do Pipeline

1. *Extra√ß√£o (Bronze)*  
   - Conex√£o com a *API do Governo (Portal da Transpar√™ncia)*.  
   - Armazenamento em formato *JSON* no bucket *bronze* do MinIO.  

2. *Transforma√ß√£o (Silver)*  
   - Processamento com *PySpark*.  
   - Limpeza, padroniza√ß√£o e enriquecimento dos dados.  
   - Salvo em formato *Parquet* no bucket *silver*.  

3. *Modelagem (Gold)*  
   - Cria√ß√£o de *tabelas dimensionais* (dim_municipio, dim_uf).  
   - Constru√ß√£o da *tabela fato* (fato_bolsa_familia).  
   - Armazenamento em *Parquet* no bucket *gold*.  

4. *Orquestra√ß√£o*  
   - Todo o fluxo √© *automatizado com Airflow*, que executa:
     - Extra√ß√£o da API.  
     - Transforma√ß√£o Bronze ‚Üí Silver.  
     - Constru√ß√£o dos modelos Silver ‚Üí Gold.  

---

## ‚öô Tecnologias Utilizadas

- *Apache Spark* (processamento distribu√≠do)  
- *MinIO* (Data Lake ‚Äì compat√≠vel com S3)  
- *Apache Airflow* (orquestra√ß√£o de pipelines)  
- *Postgres* (metadados do Airflow)  
- *Docker & Docker Compose* (containeriza√ß√£o e orquestra√ß√£o local)  
- *Python (PySpark, Requests)*  

---

## ‚ñ∂ Como executar localmente

1) *Subir os servi√ßos*
 Dentro da pasta do arquivo executar:
```bash
docker-compose¬†up¬†-d
Esse comando vai inicar o conteiner e instanciar todos os servi√ßos nas suas devidas portas:
Airflow (http://localhost:8088) e MinIO (http://localhost:9001) e Spark (http://localhost:8080)

Acesse: Airflow (http://localhost:8088) e MinIO (http://localhost:9001) e Spark (http://localhost:8080)
	2.	Executar a DAG
Na UI do Airflow, habilite e rode a DAG pipeline_bolsa_familia.
```
Sa√≠das:


üë©‚Äçüíª Autora

Rayane Correia ‚Äî Analytics Engineer | P√≥s-gradua√ß√£o em Engenharia de¬†Dados¬†‚Äì¬†UNIFOR

